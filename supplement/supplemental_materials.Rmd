---
title: 'Supplemental Materials: Time-varying responses of lake metabolism to light and temperature'
fontsize: 12pt
geometry: margin=1in,letterpaper
documentclass: article
mainfont: "Times New Roman"
mathfont: "Times New Roman"
graphics: true
colorlinks: true
supplemental: true
mathspec: true
author:
   - name: Joseph Phillips
affil:
   - name: Department of Integrative Biology, University of Wisconsin--Madison
output:
    bookdown::pdf_document2:
        fig_caption: yes
        number_sections: yes
        template: template.tex
        latex_engine: xelatex
        toc: yes
        toc_depth: 2
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, cache = FALSE}
# load packages
suppressPackageStartupMessages({
  library(knitr)
  library(bookdown)
  library(tidyverse)  
  library(lubridate)
})

# set directory
knitr::opts_knit$set(root.dir = normalizePath(".."))

# set theme
theme_set(theme_bw() %+replace% 
            theme(panel.grid = element_blank(),
                  strip.background = element_blank(),
                  legend.margin = margin(0,0,0,0),
                  strip.text = element_text(size=10),
                  legend.text = element_text(size=10),
                  axis.text=element_text(size=10, color="black"),
                  axis.title.y=element_text(angle = 90 ,margin=margin(0,15,0,0)),
                  axis.title.x=element_text(margin=margin(15,0,0,0))))
```

# Model fitting

## Scaling the model

### NEP

For fitting the model, I z-scored (centered on the mean and divided by the standard deviation) the observed DO concentrations and scaled the model accordingly. I then nondimensionalized the scaled model to remove the scale parameters (mean/standard deviation for the observed DO and mixing depth). This put the observed values and model parameters on unit scale, which improved the computaitonal efficiency and allowed for the use for weakly-informative priors on unit scale. I then back-transformed the scaled parameters to recover their values on the original scale.

The model for DO dynamics (eqn X in the main text) is:
$$
DO_{t+1} = DO_t+ \frac{\Delta h}{z_{mix}} \left(NEP_t+k_t(DO^{eq}_t-DO_t) \right)+\epsilon^{proc}_t
$$

where $DO_t$ is the DO concentration [$mg~O_2~m^{-3}$], $DO^{eq}_t$ is the DO concentration at saturation [$mg~O_2~m^{-3}$], $\Delta h$ = 1 hour, $NEP_t$ is the net ecosystem production [$mg~O_2~m^{-2}~h^{-1}$], $k$ [$m~h^{-1}$] is the rate of oxygen exchange, $z_{mix}$ is the mixing depth [$3.3m$], and $\epsilon_{proc}$ is the processes error [$mg~O_2~m^{-3}$]. For simplicity, only a single time index $t$ is used, rather than indexing by hour and day as in the main text.

For clarity, $DO$ is replaced with $y$ and $NEP$ with $\phi$, yielding

$$
y_{t+1} = y_t+ \frac{\Delta h}{z_{mix}}\left(\phi_t+k_t(y^{eq}_t-y_t) \right)+\epsilon^{proc}_t.
$$

Z-scoring the observed DO values by the mean ($\mu$) and standard deviation ($\tau$) of the full set of DO observations implies the following scaling of the model:

$$
\frac{y_{t+1}-\mu}{\tau} = \frac{1}{\tau} \left(y_t - \mu + \frac{\Delta h}{z_{mix}} \left(\phi_t+k_t(y^{eq}_t-y_t) \right)+\epsilon^{proc}_t \right)
$$

which can be expanded as

$$
= \frac{1}{\tau} y_t - \frac{1}{\tau}\mu + \frac{1}{\tau}\frac{\Delta h}{z_{mix}}\phi_t + \frac{1}{\tau} \frac{\Delta h}{z_{mix}} k_t (y^{eq}_t-y_t) + \frac{1}{\tau}\epsilon^{proc}_t. 
$$

Rearranging to express all "$y$" terms to resemble the lefthand side yields

$$
\frac{y_{t+1}-\mu}{\tau} = \frac{y_t-\mu}{\tau} + \frac{1}{\tau}\frac{\Delta h}{z_{mix}}\phi_t + \frac{\Delta h}{z_{mix}} k_t\left( \left(\frac{y^{eq}_t-\mu}{\tau} + \frac{\mu}{\tau} \right)- \left(\frac{y_t-\mu}{\tau} + \frac{\mu}{\tau}\right) \right) + \frac{1}{\tau}\epsilon^{proc}_t
$$

which simplifies to 

$$
\frac{y_{t+1}-\mu}{\tau} = \frac{y_t-\mu}{\tau} + \frac{1}{\tau}\frac{\Delta h}{z_{mix}}\phi_t + \frac{\Delta h}{z_{mix}} k_t\left( \frac{y^{eq}_t-\mu}{\tau} - \frac{y_t-\mu}{\tau} \right) + \frac{1}{\tau}\epsilon^{proc}_t. 
$$

Substituting with scaled variables yields

$$
x_{t+1} = x_t + \hat{\phi_t} + \hat{k}_t (x^{eq}_t - x_t) + \hat{\epsilon}^{proc}_t
$$
where 

\begin{equation}
\begin{split}
&x_t = \frac{y_t-\mu}{\tau}  \\
&x^{eq}_t = \frac{y^{eq}_t-\mu}{\tau} \\
&\hat{\phi}_t = \frac{1}{\tau}\frac{\Delta h}{z_{mix}}\phi_t \\
&\hat{k}_t = \frac{\Delta h}{z_{mix}} k_t \\
&\hat{\epsilon}^{proc}_t = \frac{1}{\tau}\epsilon^{proc}_t
\end{split}
\end{equation}

The parameter values on the original scale can be obtained by back-transforming the scaled values. For example, $\phi_t = \tau\frac{z_{mix}}{\Delta h} \hat{\phi}_t$.

###GPP and ER

NEP ($\phi_t$) is the difference between GPP and ER. Therefore, the scaling of NEP implies that GPP (denoted $\chi$) and ER (denoted $\kappa$) are scaled as 

\begin{equation}
\begin{split}
\hat{\chi}_t = \frac{1}{\tau}\frac{\Delta h}{z_{mix}}\chi_t\\
\hat{\kappa}_t = \frac{1}{\tau}\frac{\Delta h}{z_{mix}}\kappa_t\\
\end{split}
\end{equation}

The original equation for $\chi$ (main text eqn X) is

$$
\chi_t = \beta_{d}~\text{tanh} \left( \frac{\alpha_t}{\beta_t}L_t\right)  
$$ 

where $\beta_t$ is the maximum rate of GPP [$mg~O_2~m^{-3}~h^{-1}$] on a particular day and $\alpha$ [$mg~O_2~s~\mu mol~photons^{-1}~m^{-1}~h^{-1}$] is the rate at which GPP increases with $L_t$. This is scaled as

$$
\hat{\chi}_t = \frac{1}{\tau}\frac{\Delta h}{z_{mix}}\beta_t~\text{tanh} \left( \frac{\frac{\lambda}{\tau}\frac{\Delta h}{z_{mix}}\alpha_t}{\frac{1}{\tau}\frac{\Delta h}{z_{mix}}\beta_t}\frac{L_t}{\lambda}\right)  
$$ 

where $\lambda$ is the mean light level (so that $\alpha_t$ can be expressed on unit scale). This simplifies to 

$$
\hat{\chi}_t = \hat{\beta}_t~\text{tanh} \left( \frac{\hat{\alpha}_t}{\hat{\beta}_t}\hat{L}_t\right)  
$$ 

where 
\begin{equation}
\begin{split}
&\hat{\beta}_t = \frac{1}{\tau}\frac{\Delta h}{z_{mix}}\beta_t\\
&\hat{\alpha}_t = \frac{\lambda}{\tau}\frac{\Delta h}{z_{mix}}~\alpha_t\\
&\hat{L}_t = \frac{L_t}{\lambda}.
\end{split}
\end{equation}

This scaling can be applied by direct analogy to ER and to the time varying components of $\beta_t$, $\alpha_t$, and $\rho_t$ (main text eqns X-X)

## Priors

I fit the model using weakly informative priors based on normal distributions (see http://mc-stan.org/users/documentation/case-studies/weakly_informative_shapes.html). Because the parameters were fit on unit scale, I was generally used priors with standard deviations of 1 and means of 0. However, because the parameters describing the scaling of GPP and ER with temperature ($\gamma_\beta$ and $\gamma_\rho$) had lower bounds of 1, I used corresponding priors with means of 1. For those parameters with lower bounds (1 for $\gamma_\beta$ and $\gamma_\rho$ and 0 for all standard deviations), I used normal priors truncated at their respective lower bounds. 

## Estimating observation error

Attempting to estimate the standard deviaitons for observation error ($\sigma_{obs}$) and process error ($\sigma_{proc}$) independently resulted in very inefficient sampling of the posterior distribution as $\sigma_{obs}$ slowly converged to 0. This can be seen by examining the parameter trace plots from the MCMC (Fig \ref{fig:trace}). While $\sigma_{proc}$ showed good mixing across all four chains, the chains for $\sigma_{proc}$ did not mix, indicating a lack of convergence. However, the overall magnitude of $\sigma_{obs}$ was close to 0 and the lack of convergence is likely due to difficulties associated with estimating the parameter when near it's boundary.

Therefore, I refit the model fixing $\sigma_{obs}$ to near 0 (1% of the observed standard deviation in obseved DO, so that I could use the same model specification in Stan). This resulted in nearly identical estimates for the parameters (Fig \ref{fig:posts-sig-obs}). 

```{r trace, echo = FALSE, message = FALSE, cache = FALSE, fig.height=4, fig.width=6, fig.cap="Trace plots for standard deviations of observation and process error from the MCMC. Colors indicate separately initialized chains."}
read_csv("analyses/model_fit/output/sig_obs/fixed_pars_full.csv") %>%
  select("chain","step","sig_obs","sig_proc") %>%
  rename("sigma[obs]" = "sig_obs", "sigma[proc]" = "sig_proc") %>%
  gather(par, value, -chain, -step) %>%
  ggplot(aes(step, value, color=factor(chain)))+
  facet_wrap(~par, scales="free_y", labeller = label_parsed)+
  geom_line(alpha=0.4)+
  scale_color_manual(values=c("blue","black","orange","red")) +
  ylab("Value")+
  xlab("Iteration")+
  guides(color = F)
```

```{r posts-sig-obs, echo = FALSE, message = FALSE, cache = FALSE, fig.height=6, fig.width=5, fig.cap="Posterior distributions for parameter estimates, with the standard deviation of observation error estimated from data or fixed to 0."}
read_csv("analyses/model_fit/output/sig_obs/fixed_pars_full.csv") %>%
  select(-"lp__",-"sig_obs") %>%
  mutate(type = "Estimated") %>%
  bind_rows(read_csv("analyses/model_fit/output/fixed_pars_full.csv") %>%
  select(-"lp__") %>%
  mutate(type = "Fixed to 0")) %>%
  rename("gamma[beta]" = "gamma_1", "gamma[rho]" = "gamma_2",
         "sigma[alpha]" = "sig_a", "sigma[beta[0]]" = "sig_b0",
         "sigma[rho]" = "sig_r", "sigma[proc]" = "sig_proc") %>%
  gather(var, value, -step, -chain, -type) %>%
  ggplot(aes(value, linetype = type))+
  facet_wrap(~var, scales = "free", labeller = label_parsed)+
  stat_density(aes(linetype = type), position = "identity", geom = "line")+
  scale_y_continuous("Posterior Probability Density", breaks=NULL)+
  scale_x_continuous("Value", breaks=NULL)+
  scale_linetype_manual(expression(sigma[obs]), values=c(1,2))+
  theme(legend.position="top", legend.direction = "vertical")
```

## Stan specifications and diagnostics

Detailed explanation of code for specifying, fitting, and diagnosing the model with Stan can be found at: 

\clearpage

# Simulations

## Methods

A main objective of the analysis was to infer the temporal variation in the parameters of the P-I curve ($\beta_d^0$, $\alpha_d$, and $rho_d$), with the magnitude of variation characterized by the standard deviations of the respective stochastic processes ($\sigma_\beta$, $\sigma_\alpha$, and $\sigma_\rho$). To explore the capacity of the model to distinguish real changes in these parameters from noise, I fit the model to simulated data with $\beta_d^0$, $\alpha_d$, and $rho_d$ fixed to their mean values for each year as inferred by the fit of the model to real data. The simulated data implied that $\sigma_\beta$, $\sigma_\alpha$, and $\sigma_\rho$ had “true” values of 0; therefore, the model fit to these data should produce estimates shifted toward 0 relative to the estimates for the actual data. 

The goal was to validate the model as fit to the particular data used in this analysis. Therefore, I constructed the simulated data using the observed environmental data and the particular sequence of process errors (i.e. $\epsilon^{proc}_d$) as inferred from the model fit to the original data. The observed DO for each year had gaps due to missing data, which resulted in many contiguous time-series within each year. For the simulated data, I retained this structure as it could have implications for the efficacy of the model fitting. Initial values for the first time-series in each year were set to the corresponding value in the observed data. However, for the initial values of all subsequent time-series within a year I projected the model as if there were no gap in the data (such that each year would have a single contiguous stretch of observations) and then inserted gaps into the simulated time-series to match the structure of the original data. This is was necessary as using the observed values to initial each time-series would lead to substantial differences between the initial value and the equilibrium determined by metabolism rates when fixed to their means. The real and simulated data appear quite different, indicating that the temporal variation in the ecosystem metabolism parameters has large effects on the DO dynamics (Fig \ref{fig:sim-data}).

Detailed explanation of code for simulated data and corresponding model fit with Stan can be found at: 

## Results

As discussed in the main text, $\sigma_\beta$, $\sigma_\alpha$, and $\sigma_\rho$ were all clearly different from 0 when estimated from the real data. In contrast, the variance estimates for the simulated data were all strongly right skewed, with posterior densities concentrated near 0 (Fig \ref{fig:sim-post}). This suggests that the temporal variation in $\beta_d^0$, $\alpha_d$, and $rho_d$ inferred by the model reflected real changes in the underlying P-I curve. 

```{r sim-data, echo = FALSE, message = FALSE, warning = FALSE, cache = FALSE, fig.height=6, fig.width=6, fig.cap="Time-series for real and simualted DO."}
# plot
read_csv("simulation/input/beta0_alpha_rho_fixed/data_export.csv") %>%
  select(year, yday, hour, do) %>%
  mutate(type = "Simulated",
         do = do) %>%
  bind_rows(read_csv("analyses/model_fit/input/sonde_prep.csv") %>%
              select(year, yday, hour, do) %>%
              mutate(type = "Real")) %>%
  mutate(time = yday + hour/24) %>%
  ggplot(aes(time, do, color = type))+
  facet_wrap(~year)+
  geom_line(alpha = 0.7, size = 0.5)+
  scale_color_manual("",values=c("forestgreen","black"))+
  scale_y_continuous(expression(DO~"("*mg~O[2]~L^{-1}*")"))+
  scale_x_continuous("Day of Year")+
  theme(legend.position = c(0.9, 0.92))
```

```{r sim-post, echo = FALSE, message = FALSE, warning = FALSE, cache = FALSE, fig.height=6, fig.width=4, fig.cap="Time-series for real and simualted DO."}
# prepare data
sig_par = read_csv("analyses/model_fit/output/fixed_pars_full.csv") %>%
  select(sig_b0, sig_a, sig_r) %>%
  gather(var, value) %>%
  mutate(type = "Time-Varying") %>%
  bind_rows(read_csv("simulation/output/beta0_alpha_rho_fixed/fixed_pars_full.csv")  %>%
              select(sig_b0, sig_a, sig_r) %>%
              gather(var, value) %>%
              mutate(type = "Fixed")) 

# create dummy data to set y-axis range
dummy_lab = data_frame(var = c("sig_b0","sig_a","sig_r"),
                       label = c("","",""),
                       value = c(0.2, 0.2, 0.2),
                       y = c(145, 45, 110))

# create labels
sig_lab = data_frame(var = c("sig_b0","sig_a","sig_r"),
                     label = c("sigma[beta]~(max~GPP)", 
                               "sigma[alpha]~(initial~slope)",
                               "sigma[rho]~(baseline~ER)"),
                     value = c(0.2, 0.2, 0.2),
                     y = 0.9*dummy_lab$y)

# plot
sig_par %>%
  ggplot(aes(value))+
  facet_wrap(~var, labeller = label_parsed, nrow = 3, scales = "free_y")+
  stat_density(aes(linetype = type), position = "identity", geom = "line")+
  scale_y_continuous("Posterior Probability Density", breaks = NULL)+
  scale_x_continuous("Value (Dimensionsless)", breaks = seq(0,0.4,0.1), limits = c(0,0.4))+
  geom_text(data = dummy_lab, aes(label = label, y = y), position = "identity")+
  geom_text(data = sig_lab, aes(label = label, y = y), position = "identity", parse = T)+
  scale_linetype_manual("", values = c(2,1))+
  theme(legend.position = c(0.75,0.87),
        strip.text=element_blank())
```

\clearpage

# Surface vs. average water column PAR

## Methods

Because primary production occurs throughout the water column and in the benthos, I fit the model using the average water column light, calcualted as 

$$
\begin{aligned}
&\overline{L_{d,h}(z)} = \frac{1}{z_\text{max}} \int_0^{z_\text{max}} L^0_{d,h}~e^{-c_{d,h}~z}~dz =  \frac{L^0_{d,h}(1-e^{-c_d,h~z_\text{max}})}{z_\text{max}~c_{d,h}}
\end{aligned}
$$
where $z$ [$m$] is the vertical position in the water column, $z_{max}$ is the water column depth, $L^0_{d,h}$ is the PAR at the water surface $(z=0)$, and $c_{d,h}$ is the light attenuation coefficient (we used $c$ rather than the standard $k_d$ to avoid notational confusion with gas exhange constants used below). For notational simplicity, we henceforth denote $\overline{L_{d,h}(z)}$ as $L_{d,h}$. To estimate $c_{d,h}$, I regressed observe light attenuation calculated from weekly measurements of PAR at 0.5m depth intervals against turbidity and used this regression (y = 0.43 + 0.059 $\times$ turbidity; df = 34; $R^2$ = 0.66) to predict $c_{d,h}$ from turbidity for each time point in the sonde data. 

The estimates $\overline{L_{d,h}(z)}$ have some uncertainty to do the inference of water clarity from turbidity. Furthermore, it is common in other studies of ecosystem metaboslim to use light as measured near the water surface. To evaluate the consequences of using $\overline{L_{d,h}(z)}$, I refit the model to surface light ($L^0_{d,h}$) and compared the estimates of the time-varying parameters to those for the original model fit. 

## Results

The estimates of baseline ER and maximum GPP were almost identical for both surface and water column light, as they should be given that they characterize metabolism when light is 0 (i.e. when surface and water column light are the same) and when light is saturating (i.e. when differences between surface and water column later are irrelevant) (Fig \ref{fig:beta0-rho}). The average value of the initial slope of the P-I curve was substantially lower for the model fit using surface light, which again was as expected since the surface light values were always higher than the water column values (Fig \ref{fig:alpha}). However, the temporal patterns were very similar, with the largest differences being relatively high values in 2015 and 2018 when using the water column light. These two years had substantial declines in water column light due to reduced water clarity associated with cyanobacterial blooms. 

```{r beta0-rho, echo = FALSE, message = FALSE, warning = FALSE, cache = FALSE, fig.height=6, fig.width=6, fig.cap="Ecosystem metabolism rates estimated using either surface or average water column light."}

# prepare data
beta_rho_d = read_csv("analyses/model_fit/output/summary_clean.csv") %>%
  filter(name %in% c("beta0","rho")) %>%
  left_join(read_csv("analyses/model_fit/input/sonde_prep.csv") %>%
              filter(is.na(unique_day)==F) %>%
              group_by(year, yday) %>%
              summarize(day = unique(unique_day))) %>%
  mutate(type = "Water Column") %>%
  bind_rows(read_csv("analyses/model_fit/output/surface_par/summary_clean.csv") %>%
  filter(name %in% c("beta0","rho")) %>%
  left_join(read_csv("analyses/model_fit/input/sonde_prep.csv") %>%
              filter(is.na(unique_day)==F) %>%
              group_by(year, yday) %>%
              summarize(day = unique(unique_day))) %>%
    mutate(type = "Surface"))

# plot
beta_rho_d %>%
  ggplot(aes(yday, middle, color=name))+
  facet_wrap(~year)+
  geom_line(aes(linetype = type, size = type), alpha = 0.7)+
  geom_text(data = data_frame(year = 2015, yday = 187, 
                              name = c("beta0","beta0","rho","rho"), 
                              middle = c(490, 410, 240, 160)), 
            aes(color = name), 
            label=c("Max GPP",expression((beta^0)), "Basline ER", expression((rho))), 
            hjust = 0)+
  scale_y_continuous(expression(Metabolism~Parameter~"("*mg~O[2]~m^{-2}~h^{-1}*")"))+
  scale_color_manual("",values=c("dodgerblue","firebrick2"), guide = F)+
  scale_linetype_manual("",values=c(2,1))+
  scale_size_manual(values=c(0.7, 0.4))+
  scale_x_continuous("Day of Year", breaks = c(170, 200, 230), limits = c(150, 250))+
  guides(size = F)+
  theme(legend.position = c(0.82,0.91))
```

```{r alpha, echo = FALSE, message = FALSE, warning = FALSE, cache = FALSE, fig.height=6, fig.width=6, fig.cap="Initial slope of the P-I curve estimated using either surface or average water column light."}

# prepare data
alpha_d = read_csv("analyses/model_fit/output/summary_clean.csv") %>%
  filter(name %in% c("alpha")) %>%
  left_join(read_csv("analyses/model_fit/input/sonde_prep.csv") %>%
              filter(is.na(unique_day)==F) %>%
              group_by(year, yday) %>%
              summarize(day = unique(unique_day))) %>%
  mutate(type = "Water Column") %>%
  bind_rows(read_csv("analyses/model_fit/output/surface_par/summary_clean.csv") %>%
  filter(name %in% c("alpha")) %>%
  left_join(read_csv("analyses/model_fit/input/sonde_prep.csv") %>%
              filter(is.na(unique_day)==F) %>%
              group_by(year, yday) %>%
              summarize(day = unique(unique_day))) %>%
    mutate(type = "Surface"))

# plot
alpha_d %>%
  filter(name %in% c("alpha")) %>%
  ggplot(aes(yday, middle))+
  facet_wrap(~year)+
  geom_line(aes(linetype = type, size = type), alpha = 0.7)+
  scale_linetype_manual("",values=c(2,1))+
  scale_size_manual(values=c(0.7, 0.4))+
  scale_y_continuous(expression(Initial~Slope~(alpha)~"("*mg~O[2]~s~mu*mol-photons^{-1}~h^{-1}*")"))+
  scale_x_continuous("Day of Year", breaks = c(160, 190, 220))+
  guides(size = F)+
  theme(legend.position = c(0.14,0.91))
```

# Drivers of maximum GPP

Maximum GPP at high light $\beta_d^0$ was quite variable, and it was the dominant contributor to variation in overall GPP and NEP. In the main text, I report results from linear models regressing $\beta_d^0$ against daily mean phycocyanin (as a measure of cyanobacterial abundance) and larval midge abundance. Phycocyanin data were available for all days for which there were estimates of $\beta_d^0$, while midge data were only available approximately weekly. Therefore, I fit two models: (1) including phycocyanin for all days, and (2) including both phycocyanin and midge abundance for those days when midge samples were collected. In the main text I show a figure relating $\beta_d^0$ against phycocyanin for all days. Here I show the corresponding figure for those days where midges were samples (Fig \ref{fig:midges}).

```{r midges, echo = FALSE, message = FALSE, warning = FALSE, cache = FALSE, fig.height=6, fig.width=6, fig.cap="Time-series of maximum GPP (as inferred from the model), phycocyanin, and midge larva."}

# prepare beta0 and phycocyanin data
beta0_phyc = read_csv("analyses/model_fit/output/summary_clean.csv") %>%
  filter(name %in% c("beta0")) %>%
  left_join(read_csv("analyses/model_fit/input/sonde_prep.csv") %>%
              filter(is.na(unique_day)==F) %>%
              filter(pcyv < 0.3) %>%
              group_by(year, yday) %>%
              summarize(day = unique(unique_day),
                        pcyv = mean(pcyv))) %>%
  select(year, yday, middle, pcyv) %>%
  rename(beta0 = middle) 

# prepare midge data
midges_summary = read_csv("data/midges.csv") %>%
              filter(sta %in% c(3, 33)) %>%
              mutate(year = year(sampledate),
                     yday = yday(sampledate)) %>%
              group_by(year, yday, coreid) %>%
              summarize(tanyt = sum(tanyt/fract_count),
                        chiro = sum(chiro/fract_count),
                        midges = tanyt + chiro) %>%
              group_by(year, yday) %>%
              summarize(tanyt = mean(tanyt, na.rm=T),
                            chiro = mean(chiro, na.rm=T),
                            midges = mean(midges, na.rm=T))

# combine 
beta0_phyc_midge = beta0_phyc %>%
  left_join(midges_summary) %>%
  na.omit()

# plot
beta0_phyc_midge %>%
  gather(var, val, beta0, pcyv, midges) %>%
  group_by(var) %>%
  mutate(val = (val - mean(val, na.rm=T))/sd(val, na.rm=T)) %>%
  ungroup() %>%
  mutate(var = factor(var, levels=c("beta0","pcyv","midges"), labels=c("Max GPP", "Phycocyanin", "Midges"))) %>%
  ggplot(aes(yday, val, color = var))+
  facet_wrap(~year)+
  geom_line()+
  scale_color_manual("",values = c("black","cyan4","magenta4"))+
  scale_y_continuous("Z-Score (dimensionless)", breaks = NULL)+
  scale_x_continuous("Day of Year", breaks = c(160, 190, 220))+
  theme(legend.position = c(0.14, 0.88))
```













